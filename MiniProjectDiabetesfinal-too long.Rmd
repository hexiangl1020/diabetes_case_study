---
title: "Predicting readmission probability for diabetes inpatients"
author: "Modern Data Mining"
date: ' '
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
    fig_width: 1.5 
    fig_height: 1 
  html_document:
    code_folding: show
    highlight: haddock
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 6, fig.height = 3)
if(!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, ggplot2, glmnet, car, data.table)   #add your packages here
```
# Executive Summary

**Diabetes Introduction**
Diabetes is a chronic medical condition that consists of two sub-types with distinct etiology. Type II diabetes is more common and develops slowly as insulin resistance builds. As a result, the body needs more insulin to transport glucose from blood to metabolic organ tissues.  Prediabetes occurs when the blood glucose is higher than normal (over 100 fasting) but has not advanced to the clinical criterion for diabetes. This is a critical stage of intervention, as lifestyle modifications and medication can delay disease progression. Diagnosis for diabetes is based on a series of clinical tests. Fasting plasma glucose is a point in time measurement that is taken after 8 hours of fasting. A more reliable diagnostic tool is the A1C test, that provides an average of blood glucose over 3 months. Normal A1C is below 5.7% and 6.5% or higher indicates a diabetes diagnosis.

**Health Policy** 
During the implementation of the ACA, several policies were enacted to limit government expenditure on healthcare. These interventions targeted the most expensive treatments that could be prevented with better provider management and coordination, including hospitalizations. Should a patient be readmitted to the hospital within 30 days of a prior admission with the same clinical diagnosis, government sponsored insurance would not reimburse for clinical care provided. Health systems were thereafter financially incentivized to provide improved discharge planning, coordinated community-based care and additional therapeutic supports to reduce the likelihood of readmission. One strategy is developing predictive models to understand which patients that were most at risk for critical complications following hospitalization. Additional clinical interventions could then be allocated to these patients to reduce both disease burden and costs of future treatment that may not be reimbursed under this new policy. 

**Data Source**
Using data from 130 hospitals across the United States from 1999-2008, this report will generate a predictive model that can be systematically applied to hospitalizations with a primary diagnosis of diabetes. Inclusion criterion for observations include patient hospitalization of 1 to 14 days, evaluation with laboratory tests, medication administration and diabetes diagnosis. There are over 100,000 hospital admissions of approximately 70,000 patients included in the analysis. 
```{r, include=FALSE}

library(dplyr)
readmission<-read.csv('readmission.csv') %>%
  rename(age="age_mod") #rename the variable for convenience

summary(readmission)
#change <30 to 1, otherwise to 0
readmission<- readmission %>% mutate(readmitted = ifelse(readmitted %in% "<30", 1, 0))
readmission <- readmission %>% mutate_if(is.character,as.factor)
readmission$readmitted<-as.factor(readmission$readmitted)
str(readmission)
dim(readmission)
#one big problem of this data is #of 0 is 9 fold of #of 1. Unbalanced!
```
**For our analysis, we use the cleaned readmission data sets, which excludes several relatively not significant variables and bins ICD9 codes for simplification.** We also categorized readmission rate into two levels from its original three level order, with "1" indicating a readmission period <= 30 days after discharge, and "0" indicating either not readmitted or readmitted >= 30 days after discharge. We noticed that there are almost 9 folds of "0"s than "1"s in this data, meaning there are only a small portion of patients are readmitted less than 30 days of discharge. This huge difference in "0" and "1" reveals an unbalanced nature of this data set, which might influence the accuracy of the final trained model. 

# Exploratory Data Analysis
Before diving into detailed analysis, we first take a look at the demographic and hospital admission features of this data set. We counted the frequency based on difference levels for these variables.For demographic aspects, the majority of this readmission data is collected from female group than male group, despite the prevailing fact that diabetes is more common in male than in female patients. This could be either a bias results from data collection methods. Regarding age difference in this data set, the majority has a age ranging from 20 to 79, which is in accordance with age group with most diabetes occurrence. For admission features, most readmission sources are from emergency rooms and the type being emergency, indicating a quite severe level of disease condition.
```{r, include=FALSE}
# We first look into the demographic features of this data sets
readmission %>%count(gender)
# readmission %>%count(race)
readmission %>%count(age)
readmission %>%count(adm_src_mod)
readmission %>%count(adm_typ_mod)
```

**Graphical and Quantitative Summary for Potential Diabetes Readmission Factors**
There are several numerical variables in this data set, such as time patients spend in hospital, numbers of medications they are taking, numbers of lab procedures, and numbers of different medical treatment history. We analyse the mean value of these numerical variables between readmission groups. Based on these mean values, we try to see how are these numbers related to readmission time span. Evident variances lie in **number of emergency** and **in-patient medical visits**. For patients that have readmission less than 30 days, they tend to have double amount of emergency and inpatient visits than those who are readmitted more than 30 days 
```{r, include=FALSE}
# see the potential relationship how the numerical variables will influence readmission rate
df1 <- readmission %>% group_by(readmitted)  %>% summarise(Mhosptime=mean(time_in_hospital),Mnummed=mean(num_medications),Mlabprocedure=mean(num_lab_procedures),Mprocedure=mean(num_procedures),Moutpatient=mean(number_outpatient),Memergency=mean(number_emergency), Minpatient=mean(number_inpatient), Mnum_of_diag=mean(number_diagnoses))

df1
```

```{r, echo=FALSE, warning = FALSE}
read_plot<-readmission[,c(5,8,9,11,12,31)]
p_data<-melt(read_plot,id=c(6),d.vars='Label')
p <- ggplot(data = p_data, aes(x=readmitted, y=value)) + 
             geom_boxplot(aes(fill=readmitted))
p + facet_wrap( ~ variable, scales="free_y")
```
```{r, echo=FALSE}
# p2 <- readmission %>% mutate(readmitted = as.numeric(readmitted)-1) %>%
#   ggplot(aes(x=num_medications, y=readmitted)) +
#   geom_jitter(height = .05, aes(color = factor(readmitted)))+
#   geom_smooth(method = "lm", se = FALSE) +
#   ylab("Prob(readmitted=1)")

p7 <- readmission %>% mutate(readmitted = as.numeric(readmitted)-1) %>%
  ggplot(aes(x=number_inpatient, y=readmitted)) + 
  geom_jitter(height = .05, aes(color = factor(readmitted)))+
  geom_smooth(method = "lm", se = FALSE) +
  ylab("Prob(readmitted=1)")

p7

```
Based on these jitter plots(Appendix) we can see that for patients that are readmited into hospital within 30 days, they tend to have taken more medications and more lab procedures. And they also tend to have more medical visits in all forms compared with those that are not readmitted as frequently, indicating a severe diabetes case,

To understand how ordered/categorical variables such as "gender", "age" and "change" in medication influence readmission, we also count the frequency in each readmission group, and plot their counts as shown in the following:
```{r, include=FALSE}
t1 <- readmission %>% group_by(readmitted)  %>% count(gender)
# readmission %>% group_by(gender)  %>% count(readmitted)
# readmission %>% group_by(readmitted)  %>% count(race)
t2 <- readmission %>% group_by(readmitted)  %>% count(age)
t3 <- readmission %>% group_by(readmitted)  %>% count(change)
# readmission %>% group_by(change)  %>% count(readmitted)
t4 <- readmission %>% group_by(readmitted)  %>% count(insulin)

```

```{r, echo=FALSE}
# pic1 <- readmission %>%
#   # group_by(readmitted) %>%
#   ggplot(aes(x = readmitted, fill = gender)) +
#   geom_bar(position = "fill") +
#   ggtitle("Readmission vs Patient Gender")

pic2 <- readmission %>%
  ggplot(aes(x = readmitted, fill = age)) +
  geom_bar(position = "fill") +
  ggtitle("Readmission vs Patient Age")

# pic3 <- readmission %>%
#   ggplot(aes(x = readmitted, fill = insulin)) +
#   geom_bar(position = "fill") +
#   ggtitle("Readmission vs Insulin Use")

pic4 <- readmission %>%
  ggplot(aes(x = readmitted, fill = change)) +
  geom_bar(position = "fill") +
  ggtitle("Readmission vs Patients' Change in Medication")

cowplot::plot_grid(pic2,pic4)
```
It seems that for patients readmitted within 30 days, their age group is majorly in 60-79 and their medication plans tend to have been changed during the treatment, especially the level of insulin used. (See appendix for more plots)

**EDA Summary**
From the above analysis from numerical and ordered variables in this data set, we identify several potential contributing factors for patient readmission rate <= 30 days after their first discharge, namely: age, change of medication, numbers of medication, length of stay in the hospital, numbers of medical visits. In the following parts, we will build models based on this information.

# Analysis
```{r, include=FALSE}
#subset the data so we have a training, testing and validation data frame 

# Split the data into 7,2,1 ratios, randomly chosen
N <- length(readmission$readmitted)
n1 <- floor(.7*N)
n2 <- floor(.2*N)
n3 <- floor(.1*N)

#so we get the same answer each time
set.seed(10)
# Split data to three portions based on data of N above
idx_train <- sample(N, n1)
idx_no_train <- (which(! seq(1:N) %in% idx_train))
idx_test <- sample( idx_no_train, n2)
idx_val <- which(! idx_no_train %in% idx_test)
data.train <- readmission[idx_train,]
data.test <- readmission[idx_test,]
data.val <- readmission[idx_val,]
```
## Methods 
The data frame will be divided so the model can be developed and then validated. Backward regression will be used to determine the most appropriate predictors based on clinical content knowledge, with attention to significance levels at an alpha of 0.05. Based on our review of the literature, we suspect that patients who are newly started on medication during their hospitalization are more at risk for readmission. Also, we know that the comorbidity of diabetes and heart disease is an indicator of symptom severity and so number of diagnoses are likely associated with a second hospitalization within 30 days. We then develop a classification rule based on a resulting risk ratio that can be used to predict costs attributable to readmissions. We will use ROC curves and AUC to determine the best model out of two that we selected. We then experiment with misclassification thresholds. Bayes rule was used to weight a misclassification of readmission as two times as costly than a non-readmission. This information was provided by the hospital and gives us more practical information about the model prediction. We use the validation data to support the final model. 

**Model Selection**
We fit a starting model with a simple linear regression with a predictor that is likely highly associated with readmission- time in the hospital. Next we select 8  variables that are likely significant predictors based on clinical knowledge. We use backward selection to fit a final model with all significant variables. Gender is not predictive of readmission, this makes sense because there is limited evidence for variations in psychopathology for diabetes based on gender. Outpatient visits are also not significant, probably in part because access to primary care is associated with both prevention and symptom severity, which cancel each other out in regards to readmission risk. Insulin is highly significant. There is overlap in insulin administration and change of medication. If patients do not have any change in their medication, they also don't have an increase in insulin. We keep insulin also because it is more highly related to diabetes management. Our **final model** predicts readmission based on insulin management, number of emergency visits, time in hospital during the first admission, age, and number of diagnoses, which are all significant. In comparison to a null model, that none of these variables are significant predictors of readmission, can be rejected based on the chi squared value. (For detailed model selection process, refer to Appendix)
```{r, include=FALSE}

fit.start<-glm(readmitted~time_in_hospital, data.train, family=binomial(logit))

fit.final<-glm(readmitted~insulin+number_emergency+time_in_hospital+age+number_diagnoses, data.train, family=binomial(logit))
summary(fit.final,results=T)
Anova(fit.final)

fit0<-glm(readmitted~1, data.train, family=binomial)
anova(fit0,fit.final, test="Chisq")
```

```{r, echo=FALSE}
#plot of chi squared 
chi.sq.2<-fit0$deviance-fit.final$deviance
hist(rchisq(10000,10), freq =F, breaks=100)

#the blue line doesn't come up because p is very small 
abline(v=chi.sq.2, col="blue") 
abline(v=qchisq(0.95, 2), col="red")
```
Then we compared the starting and final model. And look for thresholds and false positives. Next we also assess the predictive properties of the starting and final model using the area under the curve. AUC is 0.5445 for the starting model and 0.5822 for the final model, indicating an improvement with the addition of significant predictors. (Refer to appendix)
```{r, include=FALSE}
#here we compare the starting and final model 
#ROC curve for the start and final model 
library(pROC)
fit.final.roc<-roc(data.train$readmitted,fit.final$fitted)
fit.start.roc<-roc(data.train$readmitted,fit.start$fitted)
```

```{r, echo=FALSE}
#the final fit is better than the starting model based on proximity to the y axis 
plot1 <- plot(fit.final.roc, col=1, lty=1, main="ROC")
plot(fit.start.roc, col=4, lty=2, add=T, main="ROC")

#looking at thresholds and false positives 
plot2 <- plot(fit.final.roc$thresholds, 1-fit.final.roc$specificities, col="green", pch=16, xlab="Threshold on Probability", ylab="False Positive", main="Thresholds vs. False Positive")

```

**Model Training**
Then, we use the reserved testing data to calculate probability of readmission using the starting and final models. We select a 0.15 cut off score arbitrarily after based on the mean from the models, which are similar. We could be more selective, for exampling using 0.10. We calculate confusion matrix comparing the actual and predicted values. In our final model at a threshold of 15%, 2,135 people of the 19,057 we expected not to be readmitted had a second hospital visit within 30 days.
```{r,echo=FALSE}
#making predictions using the testing data 
test.final<-predict(fit.final, data.test, type="response")
test.start<-predict(fit.start, data.test, type="response")

#mean probability of readmission 
# mean(test.final)
# mean(test.start)

#the data is very unbalanced, so this impacts the confusion matrix- gives true and false positives- we randomly picked 0.15 here, will determine a better threshold later 
test.start.pred<-ifelse(test.start>.15, "1", "0")
# table(test.start.pred,data.test$readmitted)

#same calculations for the final model 
test.final.pred<-ifelse(test.final>.15, "1", "0")
table(test.final.pred,data.test$readmitted)
```
Using the testing data, we calculate the misclassification error to determine the accuracy of the model at the 0.15 level, which is 0.84, CI (0.838, 0.848). We have a high specificity of 0.94 but this is compromised with the sensitivity, which is 0.01. When we test the model at the 0.10 threshold, the accuracy drops to 0.42. Sensitivity is the ability of the model to correctly identify patients that will be readmitted. Specificity is the ability of a test to correctly identify people who will not be readmitted. Given the the hospital probably cares more about people who will be readmitted, we are comfortable with this trade off. However, generally these psychometrics are not robust compared to industry standards. 
```{r, include=FALSE}
#confusion matrix with all of the model prediction information, including the missclassification error 
library(caret)
confusionMatrix(data=as.factor(test.final.pred),
                reference=data.test$readmitted,
                positive=levels(data.test$readmitted)[2])

#if we wanted to change the cut off from 0.10, we could retest this,
test.final.pred2<-ifelse(test.final>0.10, "1", "0")

confusionMatrix(data=as.factor(test.final.pred2),
                reference=data.test$readmitted,
                positive=levels(data.test$readmitted)[2])

#if we wanted to change the cut off from 0.10, we could retest this,
test.final.pred2<-ifelse(test.final>0.10, "1", "0")

confusionMatrix(data=as.factor(test.final.pred2),
                reference=data.test$readmitted,
                positive=levels(data.test$readmitted)[2])
```
Instead of guessing the threshold, we can use Bayes rule to establish this based on weighting the missclassification. The hospital has determined that there is a 2 fold cost difference to the health system for incorrectly predicting a readmission vs. non-readmission. We use this to optimize the threshold to 1/3, which gives us a Bayes missclassification error of 0.23. 
```{r, include=FALSE}
#instead of guessing about a cut off for missclassification, we can use Bayes rule to determine the weighting between the mistakes on both sides- here we assume that there is a 2 fold cost difference 

#using the log formula to establish the threshold- 1/3

fit.bayes<-as.factor(ifelse(test.final>1/3, "1","0")) 
MEC.bayes<-(2*sum(fit.bayes[data.test$readmitted=="1"]!="1")
            +sum(fit.bayes[data.test$readmitted=="0"]!="0"))/length(data.test$readmitted)

#this changed the missclassification based on cost information from the hospital, this gives us the classifications error, this worse but this is based on the weighting 
MEC.bayes
```
We use the reserved validation data to obtain the final AUC and prediction values. Using the final model on this data frame gives us an even better accuracy- 0.8644 CI (0.8576, 0.871). 
```{r, include=FALSE}
#this is the validation data- we compare the AUC to the testing data to be more confident in the model 
val.final<-predict(fit.final, data.val, type="response")
pROC::auc(data.val$readmitted,val.final)

val.final.predict<-ifelse(val.final>0.15, "1", "0")

confusionMatrix(data=as.factor(val.final.predict),
                reference=data.val$readmitted,
                positive=levels(data.val$readmitted)[2])

val.fit.final<-glm(readmitted~insulin+number_emergency+time_in_hospital+age+number_diagnoses, data.val, family=binomial(logit))
summary(val.fit.final,results=T)
Anova(val.fit.final)
```
## Conclusion and Recommendations
Using the validation data at the 0.05 alpha level suggests that insulin management is associated with fewer readmissions, providers may be educated on their treatment recommendations to avoid expensive care in the future. Other considerations for probability is age- the beta coefficients is the highest for patients who are between 60 and 80. The hospital may consider targeting specific preventative interventions to this age group. Number of diagnoses is also relevant- ensuring that comorbid conditions are also managed during hospitalizations for diabetes may reduce 30-day readmissions. An intervention could be implemented to increase interdiciplinary team evaluations. Number of previous emergency visits is the most relevant predictor for increased probability of readmission. This is intuitive because most patients are admitted to inpatient care through an emergency evaluation. People who are conditioned to seeking emergent care are therefore more likely to be readmitted. Assuming that the health system also manages outpatient care, providing better discharge coordination at the first hospitalization may reconnect patients with a primary care provider or endocrinologist that can evaluate and provide education outside of the hospital. Overall, the model developed can be helpful for the hospital to identify the probability of readmission for patients who present in diabetic crisis. A reallocation of resources will both reduce disease burden and lower risk for readmission, resulting in a healthier population at lower cost.  

## Limitations 
There are several limitations to this analysis. **Firstly**, data collection stopped in 2008. While it is necessary to collect modeling information before the health policy went into effect, time sensitive demographic changes are evident. The US population is aging, and even moderate increases in life expectancy are associated with diabetes symptom profiles. Cultural trends in nutrition and exercise, largely associated with work expectations, have also changed over the last 15 years.**Additionally**, the enactment of the 30-day readmission policy was part of the ACA, which extended marketplace insurance accessibility and allowed states to extend Medicaid. This led to a dramatic decrease in the percentage of uninsured Americans and undoubtedly changed cost profiles for hospital systems. **Finally**, this data did not include information about geography, including state level and rurality. There are potential confounding factors based on state level demographics and policy. Rural and community-based hospitals have different patient panels compared to large hospital systems in cities. It is very possible that distinct factors are associated with patient readmissions in these settings. **Furthermore**, the economics of healthcare institutions functions differently by hospital type. 

# Appendix

## EDAs on raw data

```{r, echo=TRUE}
# We first look into the demographic features of this data sets
readmission %>%count(gender)
# readmission %>%count(race)
readmission %>%count(age)
readmission %>%count(adm_src_mod)
readmission %>%count(adm_typ_mod)
```

### Histogram of demographic and hospital admission features for this data.

```{r, echo=FALSE}

# library(dplyr,ggplot)
# # Histograms for this general quantification
# p1 <- ggplot(readmission) + 
#   geom_bar(aes(x = factor(gender)), fill="skyblue") +
#   labs( title = "Histogram of Gender", x = "Gender" , y = "Frequency")
# p2 <- ggplot(readmission) + 
#   geom_bar(aes(x = race), fill="dark green") +
#   labs( title = "Histogram of Race", x = "Gender" , y = "Frequency")
# p3 <- ggplot(readmission) + 
#   geom_bar(aes(x = age), fill="orange") +
#   labs( title = "Histogram of Age", x = "Gender" , y = "Frequency")


ggplot(readmission, aes(x = factor(gender))) +
  geom_bar(fill="skyblue") +
  geom_text(aes(label = ..count..), stat = "count", vjust = 1.5, colour = "black")+
  labs( title = "Histogram of Gender", x = "Gender" , y = "Frequency")

ggplot(readmission, aes(x = factor(age))) +
  geom_bar(fill="darkgreen") +
  geom_text(aes(label = ..count..), stat = "count", vjust = 1.5, colour = "black")+
  labs( title = "Histogram of Age", x = "Gender" , y = "Frequency")

ggplot(readmission, aes(x = factor(adm_typ_mod))) +
  geom_bar(fill="orange") +
  geom_text(aes(label = ..count..), stat = "count", vjust = 1.5, colour = "black")+
  labs( title = "Histogram of Admission Type", x = "Gender" , y = "Frequency")

```

### Boxplot of numerical variables in the data

```{r, include=FALSE}
boxplot(time_in_hospital~readmitted, readmission)
boxplot(num_medications~readmitted, readmission)
boxplot(num_lab_procedures~readmitted, readmission)
boxplot(num_procedures~readmitted, readmission)
boxplot(number_outpatient~readmitted, readmission)
boxplot(number_emergency~readmitted, readmission)
boxplot(number_inpatient~readmitted, readmission)
boxplot(number_diagnoses~readmitted, readmission)
```

### Barplots for categorical variables
```{r, echo=FALSE}
pic1 <- readmission %>%
  # group_by(readmitted) %>%
  ggplot(aes(x = readmitted, fill = gender)) +
  geom_bar(position = "fill") +
  ggtitle("Readmission vs Patient Gender")

pic2 <- readmission %>%
  ggplot(aes(x = readmitted, fill = age)) +
  geom_bar(position = "fill") +
  ggtitle("Readmission vs Patient Age")

pic3 <- readmission %>%
  ggplot(aes(x = readmitted, fill = insulin)) +
  geom_bar(position = "fill") +
  ggtitle("Readmission vs Insulin Use")

pic4 <- readmission %>%
  ggplot(aes(x = readmitted, fill = change)) +
  geom_bar(position = "fill") +
  ggtitle("Readmission vs Patients' Change in Medication")

pic1
pic2
```

### Jitter plots of numerical variables

```{r}
p1 <- readmission %>% mutate(readmitted = as.numeric(readmitted)-1) %>%
  ggplot(aes(x=time_in_hospital, y=readmitted)) + 
  geom_jitter(height = .05, aes(color = factor(readmitted)))+
  geom_smooth(method = "lm", se = FALSE) +
  ylab("Prob(readmitted=1)")
p1

p2 <- readmission %>% mutate(readmitted = as.numeric(readmitted)-1) %>%
  ggplot(aes(x=num_medications, y=readmitted)) +
  geom_jitter(height = .05, aes(color = factor(readmitted)))+
  geom_smooth(method = "lm", se = FALSE) +
  ylab("Prob(readmitted=1)")
p2

p3 <- readmission %>% mutate(readmitted = as.numeric(readmitted)-1) %>%
  ggplot(aes(x=num_lab_procedures, y=readmitted)) + 
  geom_jitter(height = .05, aes(color = factor(readmitted)))+
  geom_smooth(method = "lm", se = FALSE) +
  ylab("Prob(readmitted=1)")
p3

p4 <- readmission %>% mutate(readmitted = as.numeric(readmitted)-1) %>%
  ggplot(aes(x=num_procedures, y=readmitted)) + 
  geom_jitter(height = .05, aes(color = factor(readmitted)))+
  geom_smooth(method = "lm", se = FALSE) +
  ylab("Prob(readmitted=1)")
p4

p5 <- readmission %>% mutate(readmitted = as.numeric(readmitted)-1) %>%
  ggplot(aes(x=number_outpatient, y=readmitted)) + 
  geom_jitter(height = .05, aes(color = factor(readmitted)))+
  geom_smooth(method = "lm", se = FALSE) +
  ylab("Prob(readmitted=1)")
p5

p6 <- readmission %>% mutate(readmitted = as.numeric(readmitted)-1) %>%
  ggplot(aes(x=number_emergency, y=readmitted)) + 
  geom_jitter(height = .05, aes(color = factor(readmitted)))+
  geom_smooth(method = "lm", se = FALSE) +
  ylab("Prob(readmitted=1)")
p6

p8 <- readmission %>% mutate(readmitted = as.numeric(readmitted)-1) %>%
  ggplot(aes(x=number_diagnoses, y=readmitted)) + 
  geom_jitter(height = .05, aes(color = factor(readmitted)))+
  geom_smooth(method = "lm", se = FALSE) +
  ylab("Prob(readmitted=1)")
p8

```

## Analysis

### Testing models
```{r,echo=TRUE}
#model selection
#note age is an ordinal variable
# names(data.train) 

library(car)

#we start with a simple linear regression based on what will likley be a highly corollated variable- time spent in the hospital. 
fit.start<-glm(readmitted~time_in_hospital, data.train, family=binomial(logit))
#next, we added these variables to the model based on a content expertise and used backward elimination

#after gender is not significant and removed in next model 
fit1<-glm(readmitted~insulin+gender+change+number_emergency+time_in_hospital+age+number_diagnoses+number_outpatient, data.train, family=binomial(logit))
summary(fit1,results=T)
Anova(fit1)

#number of outpatient visits is not very significant, removed in next model 
fit2<-glm(readmitted~insulin+change+number_emergency+time_in_hospital+age+number_diagnoses+number_outpatient, data.train, family=binomial(logit))
summary(fit2,results=T)
Anova(fit2)

#change is less significant than the other variables and may be covered by the insulin variable, removed in final model 
fit3<-glm(readmitted~insulin+change+number_emergency+time_in_hospital+age+number_diagnoses, data.train, family=binomial(logit))
summary(fit2,results=T)
Anova(fit2)

#in this model all variables are significant and intuitive 
fit.final<-glm(readmitted~insulin+number_emergency+time_in_hospital+age+number_diagnoses, data.train, family=binomial(logit))
summary(fit.final,results=T)
Anova(fit.final)

#confidence z-intervals using wald's test 
confint.default(fit.final)
```

```{r,echo=TRUE}
#chi-square test under the null hypotheses 
#null model 
fit0<-glm(readmitted~1, data.train, family=binomial)

#testing the null and final model- there is a difference between the two 
anova(fit0,fit.final, test="Chisq")
```

### Comparision between starting and final model

```{r,echo=TRUE}
#here we compare the starting and final model 
#ROC curve for the start and final model 
library(pROC)
fit.final.roc<-roc(data.train$readmitted,fit.final$fitted,plot=T,col="blue")
fit.start.roc<-roc(data.train$readmitted,fit.start$fitted,plot=T,col="blue")

#evaluating the area under the curve for the two models 
pROC::auc(fit.start.roc)
pROC::auc(fit.final.roc)
```